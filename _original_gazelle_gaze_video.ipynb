{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnRw4-Q2I48O",
        "outputId": "ca32cd6d-3e45-4de5-c65d-d3563a1f13b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting retina-face\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from retina-face) (1.26.4)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from retina-face) (5.2.0)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from retina-face) (11.0.0)\n",
            "Requirement already satisfied: opencv-python>=3.4.4 in /usr/local/lib/python3.10/dist-packages (from retina-face) (4.10.0.84)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from retina-face) (2.17.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->retina-face) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->retina-face) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->retina-face) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->retina-face) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->retina-face) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->retina-face) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=1.9.0->retina-face) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=1.9.0->retina-face) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=1.9.0->retina-face) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->retina-face) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->retina-face) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->retina-face) (3.1.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->retina-face) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (1.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow>=1.9.0->retina-face) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=1.9.0->retina-face) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=1.9.0->retina-face) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow>=1.9.0->retina-face) (0.1.2)\n",
            "Downloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: retina-face\n",
            "Successfully installed retina-face-0.0.17\n"
          ]
        }
      ],
      "source": [
        "!pip install retina-face"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "from retinaface import RetinaFace\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "class VideoGazeAnalyzer:\n",
        "    def __init__(self, use_cuda=True):\n",
        "        self.device = 'cuda' if use_cuda and torch.cuda.is_available() else 'cpu'\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Load Gazelle model\n",
        "        self.model, self.transform = torch.hub.load('fkryan/gazelle', 'gazelle_dinov2_vitl14_inout')\n",
        "        self.model.eval()\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Colors for visualization\n",
        "        self.colors = ['lime', 'tomato', 'cyan', 'fuchsia', 'yellow']\n",
        "\n",
        "    def process_frame(self, frame):\n",
        "        \"\"\"Process a single frame and return the visualization\"\"\"\n",
        "        # Convert BGR to RGB\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(frame_rgb)\n",
        "        width, height = image.size\n",
        "\n",
        "        # Detect faces\n",
        "        resp = RetinaFace.detect_faces(frame_rgb)\n",
        "        if not isinstance(resp, dict):\n",
        "            return frame  # Return original frame if no faces detected\n",
        "\n",
        "        # Extract bounding boxes\n",
        "        bboxes = [resp[key]['facial_area'] for key in resp.keys()]\n",
        "        norm_bboxes = [[np.array(bbox) / np.array([width, height, width, height])\n",
        "                       for bbox in bboxes]]\n",
        "\n",
        "        # Prepare input for Gazelle\n",
        "        img_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
        "        input_data = {\n",
        "            \"images\": img_tensor,\n",
        "            \"bboxes\": norm_bboxes\n",
        "        }\n",
        "\n",
        "        # Get model predictions\n",
        "        with torch.no_grad():\n",
        "            output = self.model(input_data)\n",
        "\n",
        "        # Visualize results\n",
        "        result_image = self.visualize_all(\n",
        "            image,\n",
        "            output['heatmap'][0],\n",
        "            norm_bboxes[0],\n",
        "            output['inout'][0] if output['inout'] is not None else None\n",
        "        )\n",
        "\n",
        "        # Convert back to BGR for OpenCV\n",
        "        result_array = np.array(result_image)\n",
        "        return cv2.cvtColor(result_array, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    def visualize_all(self, pil_image, heatmaps, bboxes, inout_scores, inout_thresh=0.5):\n",
        "        \"\"\"Visualize all detected faces and their gaze directions\"\"\"\n",
        "        overlay_image = pil_image.convert(\"RGBA\")\n",
        "        draw = ImageDraw.Draw(overlay_image)\n",
        "        width, height = pil_image.size\n",
        "\n",
        "        for i in range(len(bboxes)):\n",
        "            bbox = bboxes[i]\n",
        "            xmin, ymin, xmax, ymax = bbox\n",
        "            color = self.colors[i % len(self.colors)]\n",
        "\n",
        "            # Draw face bounding box\n",
        "            draw.rectangle(\n",
        "                [xmin * width, ymin * height, xmax * width, ymax * height],\n",
        "                outline=color,\n",
        "                width=int(min(width, height) * 0.01)\n",
        "            )\n",
        "\n",
        "            if inout_scores is not None:\n",
        "                inout_score = inout_scores[i]\n",
        "\n",
        "                # Draw in-frame score\n",
        "                text = f\"in-frame: {inout_score:.2f}\"\n",
        "                text_y = ymax * height + int(height * 0.01)\n",
        "                draw.text(\n",
        "                    (xmin * width, text_y),\n",
        "                    text,\n",
        "                    fill=color,\n",
        "                    font=None  # Using default font\n",
        "                )\n",
        "\n",
        "                # Draw gaze direction if looking in-frame\n",
        "                if inout_score > inout_thresh:\n",
        "                    heatmap = heatmaps[i]\n",
        "                    heatmap_np = heatmap.detach().cpu().numpy()\n",
        "                    max_index = np.unravel_index(np.argmax(heatmap_np), heatmap_np.shape)\n",
        "\n",
        "                    # Calculate gaze target and face center\n",
        "                    gaze_target_x = max_index[1] / heatmap_np.shape[1] * width\n",
        "                    gaze_target_y = max_index[0] / heatmap_np.shape[0] * height\n",
        "                    bbox_center_x = ((xmin + xmax) / 2) * width\n",
        "                    bbox_center_y = ((ymin + ymax) / 2) * height\n",
        "\n",
        "                    # Draw gaze target point and line\n",
        "                    draw.ellipse(\n",
        "                        [(gaze_target_x-5, gaze_target_y-5),\n",
        "                         (gaze_target_x+5, gaze_target_y+5)],\n",
        "                        fill=color,\n",
        "                        width=int(0.005*min(width, height))\n",
        "                    )\n",
        "                    draw.line(\n",
        "                        [(bbox_center_x, bbox_center_y),\n",
        "                         (gaze_target_x, gaze_target_y)],\n",
        "                        fill=color,\n",
        "                        width=int(0.005*min(width, height))\n",
        "                    )\n",
        "\n",
        "        # Convert to RGB for OpenCV compatibility\n",
        "        return overlay_image.convert('RGB')\n",
        "\n",
        "    def process_video(self, input_path, output_path, start_time=0, duration=None):\n",
        "        \"\"\"Process a video file and save the result\"\"\"\n",
        "        # Open video file\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "        # Get video properties\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        # Calculate start and end frames\n",
        "        start_frame = int(start_time * fps)\n",
        "        if duration:\n",
        "            end_frame = start_frame + int(duration * fps)\n",
        "        else:\n",
        "            end_frame = total_frames\n",
        "\n",
        "        # Set up video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(\n",
        "            output_path,\n",
        "            fourcc,\n",
        "            fps,\n",
        "            (frame_width, frame_height)\n",
        "        )\n",
        "\n",
        "        # Seek to start frame\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "        try:\n",
        "            with tqdm(total=end_frame-start_frame) as pbar:\n",
        "                frame_count = start_frame\n",
        "                while cap.isOpened() and frame_count < end_frame:\n",
        "                    ret, frame = cap.read()\n",
        "                    if not ret:\n",
        "                        break\n",
        "\n",
        "                    # Process frame\n",
        "                    processed_frame = self.process_frame(frame)\n",
        "                    out.write(processed_frame)\n",
        "\n",
        "                    frame_count += 1\n",
        "                    pbar.update(1)\n",
        "\n",
        "        finally:\n",
        "            # Clean up\n",
        "            cap.release()\n",
        "            out.release()\n",
        "            cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "rNzv4AKbI_XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "analyzer = VideoGazeAnalyzer()\n",
        "\n",
        "# Process a video file\n",
        "input_video = \"/content/movie.mp4\"  # Replace with your video path\n",
        "output_video = \"output_video.mp4\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzbkV20bJGvF",
        "outputId": "e8e1ca24-6188-4d16-a9e3-c0981fe8ead5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/fkryan/gazelle/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth\n",
            "100%|██████████| 1.13G/1.13G [00:06<00:00, 194MB/s]\n",
            "Downloading: \"https://github.com/fkryan/gazelle/releases/download/v1.0.0/gazelle_dinov2_vitl14_inout.pt\" to /root/.cache/torch/hub/checkpoints/gazelle_dinov2_vitl14_inout.pt\n",
            "100%|██████████| 12.2M/12.2M [00:00<00:00, 46.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process 10 seconds starting from 5 seconds into the video\n",
        "analyzer.process_video(\n",
        "    input_video,\n",
        "    output_video,\n",
        "    start_time=5,  # Start 5 seconds in\n",
        "    duration=10    # Process 10 seconds\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ylhf9XsJMO_",
        "outputId": "47ca0440-29bc-46f7-9514-eb393dfc3ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/250 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24-12-22 20:59:29 - Directory /root/.deepface created\n",
            "24-12-22 20:59:29 - Directory /root/.deepface/weights created\n",
            "24-12-22 20:59:29 - retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "\n",
            "  0%|          | 0.00/119M [00:00<?, ?B/s]\u001b[A\n",
            " 39%|███▉      | 46.7M/119M [00:00<00:00, 465MB/s]\u001b[A\n",
            "100%|██████████| 119M/119M [00:00<00:00, 429MB/s] \n",
            "  1%|          | 2/250 [00:13<27:27,  6.64s/it]\n"
          ]
        }
      ]
    }
  ]
}